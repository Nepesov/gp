{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38657c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import hashlib\n",
    "import threading\n",
    "import urllib.request\n",
    "from urllib.parse import urlencode, urlparse, parse_qs, urlunparse\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced5487c",
   "metadata": {},
   "source": [
    "задаем параметры, которые пригодятся нам в дальнейшем:\n",
    "выход, скок будет страниц проходить, чтобы не открывал окна, ожидание загрузки, количество параллельных окон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17088b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1\"\n",
    "OUTPUT = \"links.txt\"\n",
    "MAX_PAGES = 40\n",
    "HEADLESS = True\n",
    "PAGELOAD_TIMEOUT = 20\n",
    "N_BROWSERS = 4  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a67919",
   "metadata": {},
   "source": [
    "создаем список айдишек районов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08997297",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_id = [x for x in range(1, 132)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930ff87d",
   "metadata": {},
   "source": [
    "тут мы либо берем наш созданный но на всякий еще один сделали если не найден будет чтобы с верхним если че играться а так вообще можно убрать эту проверку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81e2626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'district_id' in globals() and isinstance(district_id, list):\n",
    "    district_ids = district_id\n",
    "elif 'district_ids' not in globals():\n",
    "    district_ids = list(range(1, 133))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5ce933",
   "metadata": {},
   "source": [
    "дальше идет подгрузка ссылок из нашего файла со ссылками проверяем содержит ли она путь и форматируем а потом в сет чтобы без дубликатов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86d3fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_existing(path=OUTPUT) -> set[str]:\n",
    "    if not os.path.exists(path): return set()\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return set(ln.strip() for ln in f if ln.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1257e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_links = load_existing(OUTPUT)     \n",
    "file_lock = threading.Lock()           \n",
    "def append_threadsafe(candidates:set[str]) -> int:\n",
    "    if not candidates: return 0\n",
    "    added = 0\n",
    "    with file_lock:\n",
    "        new = [u for u in candidates if u not in seen_links]\n",
    "        if not new: return 0\n",
    "        seen_links.update(new)\n",
    "        with open(OUTPUT, \"a\", encoding=\"utf-8\") as f:\n",
    "            for u in new:\n",
    "                f.write(u + \"\\n\")\n",
    "            f.flush()\n",
    "            os.fsync(f.fileno())\n",
    "        added = len(new)\n",
    "    return added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cabcabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_driver():\n",
    "    o = Options()\n",
    "    if HEADLESS: o.add_argument(\"--headless=new\")\n",
    "    o.page_load_strategy = \"eager\"\n",
    "    o.add_argument(\"--disable-gpu\")\n",
    "    o.add_argument(\"--no-sandbox\")\n",
    "    o.add_argument(\"--disable-dev-shm-usage\")\n",
    "    o.add_argument(\"--blink-settings=imagesEnabled=false\")\n",
    "    o.add_experimental_option(\"prefs\", {\"profile.managed_default_content_settings.images\": 2})\n",
    "    o.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/124.0 Safari/537.36\")\n",
    "    d = webdriver.Chrome(options=o)\n",
    "    d.set_page_load_timeout(PAGELOAD_TIMEOUT)\n",
    "    d.set_script_timeout(10)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ef9ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_online(timeout=4):\n",
    "    try:\n",
    "        urllib.request.urlopen(\"https://www.google.com/generate_204\", timeout=timeout)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "565922dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_get(drv, url, wait_css=None, attempts=4, sleep_base=1.5):\n",
    "    def restart_local_driver():\n",
    "        try: drv.quit()\n",
    "        except Exception: pass\n",
    "        return make_driver()\n",
    "\n",
    "    for i in range(1, attempts + 1):\n",
    "        t0 = time.time()\n",
    "        while not is_online():\n",
    "            if time.time() - t0 > 60:\n",
    "                raise TimeoutException(\"Сеть не восстановилась за 60 секунд.\")\n",
    "            time.sleep(1.5)\n",
    "        try:\n",
    "            drv.get(url)\n",
    "            if wait_css:\n",
    "                WebDriverWait(drv, 12).until(lambda d: len(d.find_elements(By.CSS_SELECTOR, wait_css)) > 0)\n",
    "            else:\n",
    "                time.sleep(1.2)\n",
    "            return drv\n",
    "        except (TimeoutException, WebDriverException) as e:\n",
    "            msg = str(e)\n",
    "            print(f\"[safe_get] попытка {i}/{attempts} неудачна: {msg[:140]}...\", file=sys.stderr)\n",
    "            time.sleep(sleep_base * i)\n",
    "            fatal = any(s in msg for s in [\n",
    "                \"ERR_INTERNET_DISCONNECTED\",\"ERR_NETWORK_CHANGED\",\"ERR_NAME_NOT_RESOLVED\",\n",
    "                \"disconnected: not connected to DevTools\",\"chrome not reachable\",\"timeout\"\n",
    "            ])\n",
    "            if fatal or i == attempts:\n",
    "                drv = restart_local_driver()\n",
    "    return drv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb498b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_scroll_to_bottom(driver, url_for_reload: str,\n",
    "                          max_same=3, sleep_between=2.0,\n",
    "                          js_attempts=3, kb_attempts=2):\n",
    "    def js_scroll_round():\n",
    "        nonlocal last_height, same\n",
    "        try:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(sleep_between)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            same = same + 1 if new_height == last_height else 0\n",
    "            last_height = max(last_height, new_height)\n",
    "            return True\n",
    "        except WebDriverException:\n",
    "            return False\n",
    "\n",
    "    def kb_scroll_round():\n",
    "        nonlocal same, last_height\n",
    "        try:\n",
    "            body = driver.find_element(By.TAG_NAME, \"body\")\n",
    "            ActionChains(driver).move_to_element(body).click(body).perform()\n",
    "            for _ in range(12):\n",
    "                body.send_keys(Keys.PAGE_DOWN); time.sleep(0.12)\n",
    "            body.send_keys(Keys.END); time.sleep(sleep_between)\n",
    "            try:\n",
    "                new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            except WebDriverException:\n",
    "                return False\n",
    "            same = same + 1 if new_h == last_height else 0\n",
    "            last_height = max(last_height, new_h)\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    last_height, same = 0, 0\n",
    "    js_fail_streak = kb_fail_streak = 0\n",
    "\n",
    "    while True:\n",
    "        ok = js_scroll_round()\n",
    "        if not ok:\n",
    "            js_fail_streak += 1\n",
    "            ok2 = kb_scroll_round()\n",
    "            kb_fail_streak = 0 if ok2 else kb_fail_streak + 1\n",
    "        else:\n",
    "            js_fail_streak = 0\n",
    "\n",
    "        if js_fail_streak >= js_attempts and kb_fail_streak >= kb_attempts:\n",
    "            print(\"↻ вкладка зависла: перезапуск драйвера и повторное открытие страницы…\")\n",
    "            try: driver.quit()\n",
    "            except Exception: pass\n",
    "            driver = make_driver()\n",
    "            driver.get(url_for_reload); time.sleep(1.5)\n",
    "            last_height = same = js_fail_streak = kb_fail_streak = 0\n",
    "            continue\n",
    "\n",
    "        if same >= max_same:\n",
    "            break\n",
    "\n",
    "    time.sleep(1.1)\n",
    "    return driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c42f3aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_url(did:int, page:int) -> str:\n",
    "    pr = urlparse(BASE); q = parse_qs(pr.query, keep_blank_values=True)\n",
    "    for k in list(q):\n",
    "        if k.startswith(\"district[\") or k == \"p\": del q[k]\n",
    "    q[\"district[0]\"] = [str(did)]\n",
    "    q[\"p\"] = [str(page)]\n",
    "    return urlunparse((pr.scheme, pr.netloc, pr.path, pr.params, urlencode(q, doseq=True), pr.fragment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "969f5cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_links(driver) -> set[str]:\n",
    "    cards = driver.find_elements(By.CSS_SELECTOR, \"a[data-name='LinkArea'], a._93444fe79c--media--9P6wN\")\n",
    "    return {(c.get_attribute(\"href\") or \"\").split(\"?\")[0] for c in cards if c.get_attribute(\"href\")}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "315dbc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_district(did: int):\n",
    "    drv = make_driver()\n",
    "    total_added = 0\n",
    "    try:\n",
    "        for p in range(1, MAX_PAGES + 1):\n",
    "            url = build_url(did, p)\n",
    "            print(f\"[did {did} | p {p}] GET {url}\")\n",
    "            drv = safe_get(drv, url, wait_css=\"body\")\n",
    "            drv = safe_scroll_to_bottom(drv, url)\n",
    "            page_links = collect_links(drv)\n",
    "            added = append_threadsafe(page_links)\n",
    "            total_added += added\n",
    "            print(f\"[did {did} | p {p}] на странице: {len(page_links)} | новых ЗАПИСАНО: {added}\")\n",
    "\n",
    "            # чтобы не проверять каждую залупу котора уже есть выходим нахуй когда 0\n",
    "            if added == 0:\n",
    "                print(f\"[did {did}] новых нет → стоп по району\")\n",
    "                break\n",
    "\n",
    "            time.sleep(random.uniform(0.15, 0.35))\n",
    "    finally:\n",
    "        try: drv.quit()\n",
    "        except Exception: pass\n",
    "    return did, total_added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a5a5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Старт. Уже в links.txt: 40337 ссылок.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was an error managing chromedriver (error decoding response body); using driver found in the cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[did 3 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=3&p=1\n",
      "[did 2 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=2&p=1\n",
      "[did 4 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=4&p=1\n",
      "[did 1 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=1&p=1\n",
      "[did 2 | p 1] на странице: 0 | новых ЗАПИСАНО: 0\n",
      "[did 2] новых нет → стоп по району\n",
      "✔ Район 2 завершён. Добавлено: 0\n",
      "[did 3 | p 1] на странице: 0 | новых ЗАПИСАНО: 0\n",
      "[did 3] новых нет → стоп по району\n",
      "✔ Район 3 завершён. Добавлено: 0\n",
      "[did 5 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=5&p=1\n",
      "[did 6 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=6&p=1\n",
      "[did 4 | p 1] на странице: 28 | новых ЗАПИСАНО: 1\n",
      "[did 4 | p 2] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=4&p=2\n",
      "[did 1 | p 1] на странице: 28 | новых ЗАПИСАНО: 1\n",
      "[did 1 | p 2] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=1&p=2\n",
      "[did 6 | p 1] на странице: 28 | новых ЗАПИСАНО: 0\n",
      "[did 6] новых нет → стоп по району\n",
      "✔ Район 6 завершён. Добавлено: 0\n",
      "[did 4 | p 2] на странице: 28 | новых ЗАПИСАНО: 2\n",
      "[did 5 | p 1] на странице: 28 | новых ЗАПИСАНО: 1\n",
      "[did 1 | p 2] на странице: 28 | новых ЗАПИСАНО: 4\n",
      "[did 4 | p 3] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=4&p=3[did 5 | p 2] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=5&p=2\n",
      "\n",
      "[did 1 | p 3] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=1&p=3\n",
      "[did 7 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=7&p=1\n",
      "[did 8 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=8&p=1\n",
      "[did 10 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=10&p=1\n",
      "[did 11 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=11&p=1\n",
      "[did 9 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=9&p=1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Старт. Уже в {OUTPUT}: {len(seen_links)} ссылок.\\n\")\n",
    "t0 = time.time()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=N_BROWSERS) as pool:\n",
    "    futures = [pool.submit(scan_district, did) for did in district_ids]\n",
    "    for fut in as_completed(futures):\n",
    "        did, added = fut.result()\n",
    "        print(f\"✔ Район {did} завершён. Добавлено: {added}\")\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"\\nГотово. В {OUTPUT}  {len(load_existing(OUTPUT))}  ссылок.\")\n",
    "print(f\"Время: {elapsed:.1f} c. Параллельных окон: {N_BROWSERS}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9cd7f5",
   "metadata": {},
   "source": [
    "тут где шард ставьте свой номер серега 2 андрей 3 барыч 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc2dcd",
   "metadata": {},
   "source": [
    "тут уже будем проходиться по каждому лоту и собирать инфу \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d8d4cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINKS_PATH = \"links.txt\"        \n",
    "CSV_PATH   = \"cian_flats.csv\"   \n",
    "\n",
    "WORKERS = 6                     \n",
    "BATCH_SIZE = 50                 \n",
    "TIMEOUT_WAIT = 5.5              \n",
    "TIMEOUT_PAGELOAD = 14           \n",
    "PAUSE = (0.12, 0.4)             \n",
    "\n",
    "\n",
    "SHARDS = 10   \n",
    "SHARD  = 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f84f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_driver():\n",
    "    # тут настройки браузера \n",
    "    opts = Options()\n",
    "    opts.page_load_strategy = \"none\"\n",
    "    opts.add_argument(\"--headless=new\")\n",
    "    opts.add_argument(\"--disable-gpu\")\n",
    "    opts.add_argument(\"--no-sandbox\")\n",
    "    opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    opts.add_argument(\"--disable-notifications\")\n",
    "    opts.add_argument(\"--mute-audio\")\n",
    "    opts.add_argument(\"--disable-extensions\")\n",
    "    opts.add_argument(\"--disable-infobars\")\n",
    "    opts.add_argument(\"--window-size=1920,1080\")\n",
    "    opts.add_argument(\"--log-level=3\")\n",
    "    # нах картинки цсс шрифты чтоб интернет не пиздили \n",
    "    opts.add_argument(\"--blink-settings=imagesEnabled=false\")\n",
    "    prefs = {\n",
    "        \"profile.managed_default_content_settings.images\": 2,\n",
    "        \"profile.managed_default_content_settings.stylesheets\": 2,\n",
    "        \"profile.managed_default_content_settings.fonts\": 2,\n",
    "        \"profile.managed_default_content_settings.plugins\": 2,\n",
    "    }\n",
    "    opts.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "    opts.add_argument(\n",
    "        \"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36\"\n",
    "    )\n",
    "\n",
    "    drv = webdriver.Chrome(options=opts)\n",
    "    drv.set_page_load_timeout(TIMEOUT_PAGELOAD)\n",
    "    drv.set_script_timeout(TIMEOUT_WAIT)\n",
    "\n",
    "    try:\n",
    "        drv.execute_cdp_cmd(\"Network.enable\", {})\n",
    "        drv.execute_cdp_cmd(\"Network.setBlockedURLs\", {\n",
    "            \"urls\": [\n",
    "                \"*.jpg\",\"*.jpeg\",\"*.png\",\"*.gif\",\"*.webp\",\"*.svg\",\n",
    "                \"*.mp4\",\"*.webm\",\"*.avi\",\"*.mkv\",\n",
    "                \"*.woff\",\"*.woff2\",\"*.ttf\",\"*.otf\",\n",
    "                \"*.css\",\"*.map\"\n",
    "            ]\n",
    "        })\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return drv\n",
    "\n",
    "def wait_any(drv, timeout=TIMEOUT_WAIT):\n",
    "    try:\n",
    "        WebDriverWait(drv, timeout).until(\n",
    "            EC.any_of(\n",
    "                EC.presence_of_element_located(LOCATORS[\"title\"]),\n",
    "                EC.presence_of_element_located(LOCATORS[\"price\"]),\n",
    "                EC.presence_of_element_located(LOCATORS[\"address\"])\n",
    "            )\n",
    "        )\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def open_url(drv, url):\n",
    "    try:\n",
    "        drv.get(url)\n",
    "        human_pause(0.15, 0.3)\n",
    "        try:\n",
    "            wait_any(drv, timeout=max(2.5, TIMEOUT_WAIT - 2))\n",
    "        finally:\n",
    "            try:\n",
    "                drv.execute_script(\"return window.stop && window.stop();\")\n",
    "            except Exception:\n",
    "                pass\n",
    "        return None\n",
    "    except TimeoutException as e:\n",
    "        try:\n",
    "            drv.execute_script(\"return window.stop && window.stop();\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        return f\"page_load_timeout: {e}\"\n",
    "    except WebDriverException as e:\n",
    "        return f\"webdriver_error: {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"unknown_open_error: {e}\"\n",
    "\n",
    "def safe_text(drv, locator, timeout=TIMEOUT_WAIT):\n",
    "    try:\n",
    "        el = WebDriverWait(drv, timeout).until(EC.presence_of_element_located(locator))\n",
    "        return el.text.strip()\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def parse_one_url(url):\n",
    "    drv = make_driver()\n",
    "    try:\n",
    "        err = open_url(drv, url)\n",
    "        data = {\"url\": url, \"_error\": err or \"\"}\n",
    "        human_pause(0.08, 0.25)\n",
    "\n",
    "        data[\"title\"]       = safe_text(drv, LOCATORS[\"title\"])\n",
    "        data[\"price\"]       = safe_text(drv, LOCATORS[\"price\"])\n",
    "        data[\"address\"]     = safe_text(drv, LOCATORS[\"address\"])\n",
    "        data[\"area\"]        = safe_text(drv, LOCATORS[\"area\"])\n",
    "        data[\"floor\"]       = safe_text(drv, LOCATORS[\"floor\"])\n",
    "        data[\"year\"]        = safe_text(drv, LOCATORS[\"year\"])\n",
    "        data[\"metro_name\"]  = safe_text(drv, LOCATORS[\"metro_name\"])\n",
    "        data[\"metro_time\"]  = safe_text(drv, LOCATORS[\"metro_time\"])\n",
    "        data[\"house_type\"]  = safe_text(drv, LOCATORS[\"house_type\"])\n",
    "\n",
    "        return data\n",
    "    finally:\n",
    "        try:\n",
    "            drv.quit()\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a3b42fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "import time, random, csv, sys, os, hashlib\n",
    "\n",
    "LOCATORS = {\n",
    "    \"title\":   (By.XPATH, \"//h1 | //h1[contains(.,'квартира') or contains(.,'Квартира')]\"),\n",
    "    \"price\":   (By.CSS_SELECTOR, '[data-testid=\"price-amount\"] span'),\n",
    "    \"address\": (By.CSS_SELECTOR, 'div[data-name=\"AddressContainer\"]'),\n",
    "    \"area\":    (By.XPATH, \"//span[contains(text(), 'Общая площадь')]/following-sibling::span\"),\n",
    "    \"floor\":   (By.XPATH, \"//span[contains(text(), 'Этаж')]/following-sibling::span\"),\n",
    "    \"year\":    (By.XPATH, \"//span[contains(text(), 'Год постройки')]/following-sibling::span\"),\n",
    "    \"metro_name\": (By.XPATH, \"(//li[@data-name='UndergroundItem'])[1]//a[contains(@class,'underground_link')]\"),\n",
    "    \"metro_time\": (By.XPATH, \"(//li[@data-name='UndergroundItem'])[1]//span[contains(@class,'underground_time')]\"),\n",
    "    \"house_type\": (By.XPATH, \"//div[@data-name='OfferSummaryInfoItem'][.//p[contains(., 'Тип дома')]]//p[2]\")\n",
    "}\n",
    "\n",
    "CSV_KEYS = [\n",
    "    \"url\",\"title\",\"price\",\"address\",\"area\",\"floor\",\n",
    "    \"year\",\"metro_name\",\"metro_time\",\"house_type\",\"_error\"\n",
    "]\n",
    "\n",
    "def human_pause(a=PAUSE[0], b=PAUSE[1]):\n",
    "    if b > 0:\n",
    "        time.sleep(random.uniform(a, b))\n",
    "\n",
    "def stable_hash(s: str) -> int:\n",
    "    return int(hashlib.md5(s.encode(\"utf-8\")).hexdigest(), 16)\n",
    "\n",
    "def read_existing_urls(path: str) -> set:\n",
    "    seen = set()\n",
    "    if not os.path.exists(path) or os.path.getsize(path) == 0:\n",
    "        return seen\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "            for row in csv.DictReader(f):\n",
    "                u = (row.get(\"url\") or \"\").strip()\n",
    "                if u:\n",
    "                    seen.add(u)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return seen\n",
    "\n",
    "def save_csv_header_if_needed(path=CSV_PATH):\n",
    "    if not os.path.exists(path) or os.path.getsize(path) == 0:\n",
    "        with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            csv.DictWriter(f, fieldnames=CSV_KEYS).writeheader()\n",
    "\n",
    "def append_csv(rows, path=CSV_PATH):\n",
    "    if not rows:\n",
    "        return\n",
    "    with open(path, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=CSV_KEYS)\n",
    "        for r in rows:\n",
    "            w.writerow({k: r.get(k, \"\") for k in CSV_KEYS})\n",
    "\n",
    "def load_links(path=LINKS_PATH):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Файл {path} не найден\", file=sys.stderr)\n",
    "        return []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [ln.strip() for ln in f if ln.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd845c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропущено уже записанных: 15608; осталось к обработке: 24738\n",
      "Шард 1/10: беру 1137 из 24738\n",
      "подготовлено: 1137 URL\n"
     ]
    }
   ],
   "source": [
    "links = load_links(LINKS_PATH)\n",
    "links = [u.strip() for u in links if u.strip()]\n",
    "\n",
    "links = list(dict.fromkeys(links))\n",
    "\n",
    "if not links:\n",
    "    raise SystemExit(\"Список ссылок пуст. Заполни links.txt\")\n",
    "\n",
    "# скипаем че у нас есть\n",
    "seen = read_existing_urls(CSV_PATH)\n",
    "if seen:\n",
    "    before = len(links)\n",
    "    links = [u for u in links if u not in seen]\n",
    "    print(f\"Пропущено уже записанных: {before - len(links)}; осталось к обработке: {len(links)}\")\n",
    "\n",
    "# для деления между компами\n",
    "if SHARDS > 1:\n",
    "    if not (1 <= SHARD <= SHARDS):\n",
    "        raise SystemExit(f\"Неверный SHARD={SHARD}; должен быть 1..{SHARDS}\")\n",
    "    shard_idx = SHARD - 1\n",
    "    links_sharded = [u for u in links if stable_hash(u) % SHARDS == shard_idx]\n",
    "    print(f\"Шард {SHARD}/{SHARDS}: беру {len(links_sharded)} из {len(links)}\")\n",
    "    links = links_sharded\n",
    "\n",
    "if not links:\n",
    "    raise SystemExit(\"Нечего обрабатывать — все ссылки уже в CSV или не попали в этот шард.\")\n",
    "\n",
    "save_csv_header_if_needed(CSV_PATH)\n",
    "print(f\"подготовлено: {len(links)} URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d884d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Старт: 1436 URL, воркеров=6, batch=50\n",
      "Сохранено 50/1436 (ошибок 0)\n",
      "Сохранено 100/1436 (ошибок 0)\n",
      "Сохранено 150/1436 (ошибок 0)\n",
      "Сохранено 200/1436 (ошибок 0)\n",
      "Сохранено 250/1436 (ошибок 0)\n",
      "Сохранено 300/1436 (ошибок 0)\n"
     ]
    }
   ],
   "source": [
    "done = 0\n",
    "errors = 0\n",
    "batch = []\n",
    "\n",
    "t0 = time.time()\n",
    "print(f\"Старт: {len(links)} URL, воркеров={WORKERS}, batch={BATCH_SIZE}\")\n",
    "\n",
    "try:\n",
    "    with ThreadPoolExecutor(max_workers=max(1, WORKERS)) as ex:\n",
    "        futures = {ex.submit(parse_one_url, u): u for u in links}\n",
    "        for fut in as_completed(futures):\n",
    "            url = futures[fut]\n",
    "            try:\n",
    "                row = fut.result(timeout=TIMEOUT_PAGELOAD + 12)\n",
    "                if row.get(\"_error\"):\n",
    "                    errors += 1\n",
    "            except Exception as e:\n",
    "                row = {\"url\": url, \"_error\": f\"future_error: {e}\"}\n",
    "                errors += 1\n",
    "\n",
    "            batch.append(row)\n",
    "            done += 1\n",
    "\n",
    "            if len(batch) >= BATCH_SIZE:\n",
    "                append_csv(batch, CSV_PATH)\n",
    "                batch.clear()\n",
    "                # короткий прогресс прямо в output\n",
    "                print(f\"Сохранено {done}/{len(links)} (ошибок {errors})\")\n",
    "\n",
    "finally:\n",
    "    if batch:\n",
    "        append_csv(batch, CSV_PATH)\n",
    "\n",
    "dt = time.time() - t0\n",
    "print(f\"Готово: {done} URL, ошибок {errors}. Файл -> {CSV_PATH}. Время: {dt:.1f} c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eec3844",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55f5e81a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cf9ed2b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "076a144f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальных адресов к геокодингу: 6148\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "\n",
    "\n",
    "import os, json, time, math, random, re\n",
    "import pandas as pd\n",
    "import requests\n",
    "from urllib.parse import quote_plus\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "API_KEY     = \"1ab6a9cccce94a78876a4293d15a05af\"   # твой ключ Geoapify\n",
    "INPUT_CSV   = \"cian_flats.csv\"\n",
    "OUTPUT_CSV  = \"cian_with_coords.csv\"\n",
    "CACHE_JSON  = \"geocode_cache_geoapify.json\"\n",
    "\n",
    "# --- 0) Читаем CSV и находим колонку с адресом ---\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# Если точное имя неизвестно — попробуем угадать\n",
    "addr_col_candidates = [c for c in df.columns if c.lower() in [\"address\", \"адрес\"] or \"address\" in c.lower() or \"адрес\" in c.lower()]\n",
    "if not addr_col_candidates:\n",
    "    raise RuntimeError(\"Не нашёл колонку с адресом. Переименуй её в 'address' или укажи имя вручную.\")\n",
    "ADDR_COL = addr_col_candidates[0]\n",
    "\n",
    "# --- 1) Чистим адреса (убираем 'На карте' и хвост после) ---\n",
    "def clean_address(s: str) -> str:\n",
    "    s = str(s)\n",
    "    # убираем \"На карте\" (любые регистры) и всё, что после\n",
    "    s = re.sub(r\"\\s*на карте.*$\", \"\", s, flags=re.IGNORECASE)\n",
    "    # нормализуем пробелы и запятые\n",
    "    s = re.sub(r\"\\s{2,}\", \" \", s)\n",
    "    s = s.strip(\" ,;\")\n",
    "    return s\n",
    "\n",
    "df[ADDR_COL] = df[ADDR_COL].astype(str).map(clean_address)\n",
    "\n",
    "# --- 2) Подготовим кэш ---\n",
    "cache = {}\n",
    "if os.path.exists(CACHE_JSON):\n",
    "    try:\n",
    "        cache = json.load(open(CACHE_JSON, \"r\", encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        cache = {}\n",
    "\n",
    "# --- 3) Геокодер Geoapify (без двойного кодирования!) ---\n",
    "session = requests.Session()\n",
    "session.headers.update({\"User-Agent\": \"Mozilla/5.0 (geo-batch)\"})\n",
    "\n",
    "BASE = \"https://api.geoapify.com/v1/geocode/search\"\n",
    "\n",
    "def geocode_one(addr, max_retries=5):\n",
    "    # если в кэше есть валидные координаты — берём\n",
    "    if addr in cache:\n",
    "        hit = cache[addr]\n",
    "        if isinstance(hit, dict) and hit.get(\"lat\") is not None and hit.get(\"lon\") is not None:\n",
    "            return hit  # валидное попадание\n",
    "\n",
    "    params = {\n",
    "        \"text\": addr,             # ВАЖНО: передаём сырой адрес, requests сам закодирует\n",
    "        \"apiKey\": API_KEY,\n",
    "        \"limit\": 1,\n",
    "        # можно сузить поиск по Москве, чтобы точность была выше:\n",
    "        # \"filter\": \"countrycode:ru\",\n",
    "        # \"bias\": \"proximity:37.617635,55.755814\",  # центр Москвы: lon,lat\n",
    "    }\n",
    "\n",
    "    backoff = 1.0\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            r = session.get(BASE, params=params, timeout=30)\n",
    "            if r.status_code == 429:\n",
    "                time.sleep(min(60, backoff) + random.random())\n",
    "                backoff *= 2\n",
    "                continue\n",
    "\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            feats = data.get(\"features\") or []\n",
    "            if feats:\n",
    "                lon, lat = feats[0][\"geometry\"][\"coordinates\"]\n",
    "                cache[addr] = {\"lat\": lat, \"lon\": lon}\n",
    "            else:\n",
    "                cache[addr] = {\"lat\": None, \"lon\": None}\n",
    "\n",
    "            # периодически сохраняем кэш\n",
    "            if attempt == 0 or attempt % 2 == 0:\n",
    "                with open(CACHE_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(cache, f, ensure_ascii=False)\n",
    "            return cache[addr]\n",
    "\n",
    "        except requests.exceptions.Timeout:\n",
    "            time.sleep(min(30, backoff) + random.random())\n",
    "            backoff *= 2\n",
    "        except requests.RequestException as e:\n",
    "            # 5xx повторим, 4xx — завершаем\n",
    "            status = getattr(e.response, \"status_code\", 500)\n",
    "            if 500 <= status < 600:\n",
    "                time.sleep(min(30, backoff) + random.random())\n",
    "                backoff *= 2\n",
    "                continue\n",
    "            cache[addr] = {\"lat\": None, \"lon\": None}\n",
    "            return cache[addr]\n",
    "\n",
    "    cache[addr] = {\"lat\": None, \"lon\": None}\n",
    "    return cache[addr]\n",
    "\n",
    "# --- 4) Идём по уникальным адресам, без “мгновенно готово” ---\n",
    "unique_addresses = (\n",
    "    df[ADDR_COL]\n",
    "    .fillna(\"\")\n",
    "    .map(str)\n",
    "    .map(str.strip)\n",
    "    .replace({\"\": pd.NA})\n",
    "    .dropna()\n",
    "    .drop_duplicates()\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "print(f\"Уникальных адресов к геокодингу: {len(unique_addresses)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50327225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 205/6148 [06:53<3:19:54,  2.02s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     17\u001b[39m     rate_limit()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[43mgeocode_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# финальный сброс кэша\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(CACHE_JSON, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 74\u001b[39m, in \u001b[36mgeocode_one\u001b[39m\u001b[34m(addr, max_retries)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_retries):\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m         r = \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m r.status_code == \u001b[32m429\u001b[39m:\n\u001b[32m     76\u001b[39m             time.sleep(\u001b[38;5;28mmin\u001b[39m(\u001b[32m60\u001b[39m, backoff) + random.random())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/requests/sessions.py:600\u001b[39m, in \u001b[36mSession.get\u001b[39m\u001b[34m(self, url, **kwargs)\u001b[39m\n\u001b[32m    592\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[32m    593\u001b[39m \n\u001b[32m    594\u001b[39m \u001b[33;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m    595\u001b[39m \u001b[33;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[32m    596\u001b[39m \u001b[33;03m:rtype: requests.Response\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    599\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/requests/sessions.py:587\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    582\u001b[39m send_kwargs = {\n\u001b[32m    583\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    584\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    585\u001b[39m }\n\u001b[32m    586\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m587\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/requests/sessions.py:701\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    698\u001b[39m start = preferred_clock()\n\u001b[32m    700\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    704\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/requests/adapters.py:489\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    488\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m         resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m            \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m            \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    502\u001b[39m     \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m    503\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    504\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(conn, \u001b[33m\"\u001b[39m\u001b[33mproxy_pool\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1395\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1393\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1394\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1395\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1396\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1397\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:325\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:286\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    288\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py:718\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m718\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    720\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1314\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1310\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1311\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1312\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1313\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1166\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1166\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "QPS = 5  # для бесплатного тарифа лучше 2–5 QPS\n",
    "DELAY = 0.5 / QPS\n",
    "last_call = 0.0\n",
    "\n",
    "def rate_limit():\n",
    "    global last_call\n",
    "    now = time.time()\n",
    "    delta = now - last_call\n",
    "    if delta < DELAY:\n",
    "        time.sleep(DELAY - delta)\n",
    "    last_call = time.time()\n",
    "\n",
    "for addr in tqdm(unique_addresses):\n",
    "    # НЕ пропускаем адреса, у которых lat/lon == None\n",
    "    if addr in cache and isinstance(cache[addr], dict) and cache[addr].get(\"lat\") is not None and cache[addr].get(\"lon\") is not None:\n",
    "        continue\n",
    "    rate_limit()\n",
    "    geocode_one(addr)\n",
    "\n",
    "# финальный сброс кэша\n",
    "with open(CACHE_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(cache, f, ensure_ascii=False)\n",
    "\n",
    "# --- 5) Мерджим в таблицу ---\n",
    "df[\"lat\"] = df[ADDR_COL].map(lambda a: (cache.get(a) or {}).get(\"lat\"))\n",
    "df[\"lon\"] = df[ADDR_COL].map(lambda a: (cache.get(a) or {}).get(\"lon\"))\n",
    "\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(\"Готово:\", OUTPUT_CSV)\n",
    "\n",
    "# Быстрый контроль:\n",
    "ok = df[\"lat\"].notna().sum()\n",
    "print(f\"Заполнено координат: {ok} из {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a62bab5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальных адресов к геокодингу: 6148\n",
      "Геокодировано: 100/5945\n",
      "Геокодировано: 200/5945\n",
      "Геокодировано: 300/5945\n",
      "Геокодировано: 400/5945\n",
      "Геокодировано: 500/5945\n",
      "Геокодировано: 600/5945\n",
      "Геокодировано: 700/5945\n",
      "Геокодировано: 800/5945\n",
      "Геокодировано: 900/5945\n",
      "Геокодировано: 1000/5945\n",
      "Геокодировано: 1100/5945\n",
      "Геокодировано: 1200/5945\n",
      "Геокодировано: 1300/5945\n",
      "Геокодировано: 1400/5945\n",
      "Геокодировано: 1500/5945\n",
      "Геокодировано: 1600/5945\n",
      "Геокодировано: 1700/5945\n",
      "Геокодировано: 1800/5945\n",
      "Геокодировано: 1900/5945\n",
      "Геокодировано: 2000/5945\n",
      "Геокодировано: 2100/5945\n",
      "Геокодировано: 2200/5945\n",
      "Геокодировано: 2300/5945\n",
      "Геокодировано: 2400/5945\n",
      "Геокодировано: 2500/5945\n",
      "Геокодировано: 2600/5945\n",
      "Геокодировано: 2700/5945\n",
      "Геокодировано: 2800/5945\n",
      "Геокодировано: 2900/5945\n",
      "Геокодировано: 3000/5945\n",
      "Геокодировано: 3100/5945\n",
      "Геокодировано: 3200/5945\n",
      "Геокодировано: 3300/5945\n",
      "Геокодировано: 3400/5945\n",
      "Геокодировано: 3500/5945\n",
      "Геокодировано: 3600/5945\n",
      "Геокодировано: 3700/5945\n",
      "Геокодировано: 3800/5945\n",
      "Геокодировано: 3900/5945\n",
      "Геокодировано: 4000/5945\n",
      "Геокодировано: 4100/5945\n",
      "Геокодировано: 4200/5945\n",
      "Геокодировано: 4300/5945\n",
      "Геокодировано: 4400/5945\n",
      "Геокодировано: 4500/5945\n",
      "Геокодировано: 4600/5945\n",
      "Геокодировано: 4700/5945\n",
      "Геокодировано: 4800/5945\n",
      "Геокодировано: 4900/5945\n",
      "Геокодировано: 5000/5945\n",
      "Геокодировано: 5100/5945\n",
      "Геокодировано: 5200/5945\n",
      "Геокодировано: 5300/5945\n",
      "Геокодировано: 5400/5945\n",
      "Геокодировано: 5500/5945\n",
      "Геокодировано: 5600/5945\n",
      "Геокодировано: 5700/5945\n",
      "Геокодировано: 5800/5945\n",
      "Геокодировано: 5900/5945\n",
      "Готово: cian_with_coords.csv  | заполнено координат: 24124 из 24138\n"
     ]
    }
   ],
   "source": [
    "import aiohttp, asyncio, time, random, json, os, re, pandas as pd\n",
    "\n",
    "API_KEY     = \"1ab6a9cccce94a78876a4293d15a05af\"\n",
    "INPUT_CSV   = \"cian_flats.csv\"\n",
    "OUTPUT_CSV  = \"cian_with_coords.csv\"\n",
    "CACHE_JSON  = \"geocode_cache_geoapify.json\"\n",
    "\n",
    "# --- 0) Читаем CSV и находим колонку с адресом ---\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "addr_col_candidates = [c for c in df.columns if c.lower() in [\"address\", \"адрес\"] or \"address\" in c.lower() or \"адрес\" in c.lower()]\n",
    "if not addr_col_candidates:\n",
    "    raise RuntimeError(\"Не нашёл колонку с адресом. Переименуй её в 'address' или укажи имя вручную.\")\n",
    "ADDR_COL = addr_col_candidates[0]\n",
    "\n",
    "def clean_address(s: str) -> str:\n",
    "    s = str(s)\n",
    "    s = re.sub(r\"\\s*на карте.*$\", \"\", s, flags=re.IGNORECASE)\n",
    "    s = re.sub(r\"\\s{2,}\", \" \", s)\n",
    "    s = s.strip(\" ,;\")\n",
    "    return s\n",
    "\n",
    "df[ADDR_COL] = df[ADDR_COL].astype(str).map(clean_address)\n",
    "\n",
    "# --- 1) Кэш ---\n",
    "cache = {}\n",
    "if os.path.exists(CACHE_JSON):\n",
    "    try:\n",
    "        cache = json.load(open(CACHE_JSON, \"r\", encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        cache = {}\n",
    "\n",
    "# --- 2) Подготовка адресов ---\n",
    "unique_addresses = (\n",
    "    df[ADDR_COL].fillna(\"\").map(str).map(str.strip)\n",
    "      .replace({\"\": pd.NA}).dropna().drop_duplicates().tolist()\n",
    ")\n",
    "\n",
    "print(f\"Уникальных адресов к геокодингу: {len(unique_addresses)}\")\n",
    "\n",
    "# --- 3) Настройки параллелизма/лимитов ---\n",
    "QPS = 5                 # безопасно для бесплатного тарифа\n",
    "BURST = 10              # сколько запросов можно держать «в полёте»\n",
    "FLUSH_EVERY = 200       # как часто сбрасывать кэш на диск\n",
    "\n",
    "BASE = \"https://api.geoapify.com/v1/geocode/search\"\n",
    "\n",
    "# Токен-бакет: ровно QPS «жетонов» в секунду на все корутины\n",
    "class TokenBucket:\n",
    "    def __init__(self, rate_per_sec:int, capacity:int):\n",
    "        self.rate = rate_per_sec\n",
    "        self.capacity = capacity\n",
    "        self.tokens = capacity\n",
    "        self.updated = time.time()\n",
    "        self.lock = asyncio.Lock()\n",
    "\n",
    "    async def take(self):\n",
    "        while True:\n",
    "            async with self.lock:\n",
    "                now = time.time()\n",
    "                # пополняем\n",
    "                delta = now - self.updated\n",
    "                self.updated = now\n",
    "                self.tokens = min(self.capacity, self.tokens + delta * self.rate)\n",
    "                if self.tokens >= 1:\n",
    "                    self.tokens -= 1\n",
    "                    return\n",
    "            # нет токенов — короткий сон\n",
    "            await asyncio.sleep(0.02)\n",
    "\n",
    "bucket = TokenBucket(rate_per_sec=QPS, capacity=max(QPS, BURST))\n",
    "\n",
    "# --- 4) Асинхронная геокод-функция ---\n",
    "async def geocode_one(session: aiohttp.ClientSession, addr: str, attempt=0):\n",
    "    # кэш с валидными координатами\n",
    "    hit = cache.get(addr)\n",
    "    if isinstance(hit, dict) and hit.get(\"lat\") is not None and hit.get(\"lon\") is not None:\n",
    "        return hit\n",
    "\n",
    "    params = {\n",
    "        \"text\": addr,\n",
    "        \"apiKey\": API_KEY,\n",
    "        \"limit\": 1,\n",
    "        # Сузим область — повысит точность и сократит ретраи:\n",
    "        \"filter\": \"countrycode:ru\",\n",
    "        # Центр Москвы (lon,lat). Поменяй при необходимости:\n",
    "        \"bias\": \"proximity:37.617635,55.755814\",\n",
    "    }\n",
    "\n",
    "    await bucket.take()  # ждём «жетон», чтобы держать реальный QPS\n",
    "\n",
    "    try:\n",
    "        async with session.get(BASE, params=params, timeout=aiohttp.ClientTimeout(total=30)) as r:\n",
    "            # Обработка 429 и Retry-After\n",
    "            if r.status == 429:\n",
    "                retry_after = r.headers.get(\"Retry-After\")\n",
    "                sleep_s = float(retry_after) if retry_after and retry_after.isdigit() else min(60, 2 ** attempt) + random.random()\n",
    "                await asyncio.sleep(sleep_s)\n",
    "                if attempt < 6:\n",
    "                    return await geocode_one(session, addr, attempt+1)\n",
    "                cache[addr] = {\"lat\": None, \"lon\": None}\n",
    "                return cache[addr]\n",
    "\n",
    "            if 500 <= r.status < 600:\n",
    "                await asyncio.sleep(min(30, 2 ** attempt) + random.random())\n",
    "                if attempt < 6:\n",
    "                    return await geocode_one(session, addr, attempt+1)\n",
    "                cache[addr] = {\"lat\": None, \"lon\": None}\n",
    "                return cache[addr]\n",
    "\n",
    "            r.raise_for_status()\n",
    "            data = await r.json()\n",
    "            feats = data.get(\"features\") or []\n",
    "            if feats:\n",
    "                lon, lat = feats[0][\"geometry\"][\"coordinates\"]\n",
    "                cache[addr] = {\"lat\": lat, \"lon\": lon}\n",
    "            else:\n",
    "                cache[addr] = {\"lat\": None, \"lon\": None}\n",
    "            return cache[addr]\n",
    "\n",
    "    except asyncio.TimeoutError:\n",
    "        if attempt < 6:\n",
    "            await asyncio.sleep(min(30, 2 ** attempt) + random.random())\n",
    "            return await geocode_one(session, addr, attempt+1)\n",
    "        cache[addr] = {\"lat\": None, \"lon\": None}\n",
    "        return cache[addr]\n",
    "    except aiohttp.ClientError:\n",
    "        cache[addr] = {\"lat\": None, \"lon\": None}\n",
    "        return cache[addr]\n",
    "\n",
    "# --- 5) Запуск пачкой с ограничением одновременных запросов ---\n",
    "async def run_all(addresses):\n",
    "    connector = aiohttp.TCPConnector(limit=BURST, ttl_dns_cache=300)\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (geo-batch)\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    }\n",
    "    tasks = []\n",
    "    done_count = 0\n",
    "\n",
    "    async with aiohttp.ClientSession(connector=connector, headers=headers) as session:\n",
    "        sem = asyncio.Semaphore(BURST)\n",
    "\n",
    "        async def worker(a):\n",
    "            nonlocal done_count\n",
    "            async with sem:\n",
    "                res = await geocode_one(session, a)\n",
    "                done_count += 1\n",
    "                # периодический флаш кэша\n",
    "                if done_count % FLUSH_EVERY == 0:\n",
    "                    with open(CACHE_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "                        json.dump(cache, f, ensure_ascii=False)\n",
    "                return res\n",
    "\n",
    "        for a in addresses:\n",
    "            # пропускаем только «валидные» попадания; None/None — переобрабатываем\n",
    "            hit = cache.get(a)\n",
    "            if not (isinstance(hit, dict) and hit.get(\"lat\") is not None and hit.get(\"lon\") is not None):\n",
    "                tasks.append(asyncio.create_task(worker(a)))\n",
    "\n",
    "        if tasks:\n",
    "            for i, _ in enumerate(asyncio.as_completed(tasks), 1):\n",
    "                await _\n",
    "                if i % 100 == 0:\n",
    "                    print(f\"Геокодировано: {i}/{len(tasks)}\")\n",
    "\n",
    "    # финальный сброс\n",
    "    with open(CACHE_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(cache, f, ensure_ascii=False)\n",
    "\n",
    "asyncio.run(run_all(unique_addresses))\n",
    "\n",
    "# --- 6) Мерджим координаты и сохраняем CSV ---\n",
    "df[\"lat\"] = df[ADDR_COL].map(lambda a: (cache.get(a) or {}).get(\"lat\"))\n",
    "df[\"lon\"] = df[ADDR_COL].map(lambda a: (cache.get(a) or {}).get(\"lon\"))\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(\"Готово:\", OUTPUT_CSV, \" | заполнено координат:\", df[\"lat\"].notna().sum(), \"из\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e251c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time, random\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Настройки ===\n",
    "INPUT_CSV   = \"cian_with_coords.csv\"          # ваш исходный файл (должны быть колонки lat, lon)\n",
    "OUTPUT_CSV  = \"cian_with_schools.csv\"   # куда сохранять результат\n",
    "CACHE_JSON  = \"overpass_cache_schools.json\"\n",
    "RADIUS_M    = 800                        # радиус поиска (метры)\n",
    "DECIMALS    = 5                          # округление координат для кэша (см ~1–2 м)\n",
    "QPS         = 0.8                        # не чаще ~0.8 запроса в секунду (≈1.25 сек/запрос)\n",
    "MAX_RETRIES = 5\n",
    "\n",
    "# Несколько зеркал Overpass — если одно «устало», идём на следующее\n",
    "OVERPASS_URLS = [\n",
    "    \"https://overpass-api.de/api/interpreter\",\n",
    "    \"https://overpass.kumi.systems/api/interpreter\",\n",
    "    \"https://z.overpass-api.de/api/interpreter\",\n",
    "    \"https://overpass.openstreetmap.ru/api/interpreter\",\n",
    "    \"https://api.openstreetmap.fr/oapi/interpreter\",\n",
    "]\n",
    "\n",
    "HEADERS = {\n",
    "    # корректно представьтесь\n",
    "    \"User-Agent\": \"amenities-counter/1.0 (contact: your_email@example.com)\"\n",
    "}\n",
    "\n",
    "# === Загрузка таблицы ===\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# Проверим наличие координат\n",
    "if not {\"lat\",\"lon\"}.issubset(df.columns):\n",
    "    raise ValueError(\"В CSV должны быть колонки 'lat' и 'lon' (числа).\")\n",
    "\n",
    "# === Кэш ===\n",
    "cache = {}\n",
    "if os.path.exists(CACHE_JSON):\n",
    "    try:\n",
    "        with open(CACHE_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "            cache = json.load(f)\n",
    "    except Exception:\n",
    "        cache = {}\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "def build_overpass_query(lat: float, lon: float, radius_m: int) -> str:\n",
    "    # Ищем школы (amenity=school) узлы/линии/отношения; для ways/relations просим center\n",
    "    return f\"\"\"\n",
    "    [out:json][timeout:60];\n",
    "    (\n",
    "      node(around:{radius_m},{lat},{lon})[amenity=school];\n",
    "      way(around:{radius_m},{lat},{lon})[amenity=school];\n",
    "      relation(around:{radius_m},{lat},{lon})[amenity=school];\n",
    "    );\n",
    "    out count;  // отдаст только число (быстро и экономно)\n",
    "    \"\"\"\n",
    "\n",
    "def overpass_count_schools(lat: float, lon: float, radius_m: int, max_retries=MAX_RETRIES) -> int:\n",
    "    # ключ кэша: округлённые координаты + радиус + тип\n",
    "    key = f\"{round(lat,DECIMALS)},{round(lon,DECIMALS)}|{radius_m}|school\"\n",
    "    if key in cache:\n",
    "        return cache[key]\n",
    "\n",
    "    query = build_overpass_query(lat, lon, radius_m)\n",
    "\n",
    "    # троттлинг\n",
    "    time.sleep(1.0 / QPS if QPS > 0 else 0)\n",
    "\n",
    "    # пробуем последовательно зеркала + ретраи\n",
    "    last_err = None\n",
    "    for attempt in range(max_retries):\n",
    "        for base in OVERPASS_URLS:\n",
    "            try:\n",
    "                resp = session.post(base, data={\"data\": query}, headers=HEADERS, timeout=90)\n",
    "                # Иногда Overpass отдаёт 429/504 — подождём и снова\n",
    "                if resp.status_code in (429, 504, 502, 503):\n",
    "                    # backoff с джиттером\n",
    "                    sleep_s = min(60, 2 ** attempt) + random.random()\n",
    "                    time.sleep(sleep_s)\n",
    "                    continue\n",
    "\n",
    "                resp.raise_for_status()\n",
    "\n",
    "                data = resp.json()\n",
    "                # Ответ с out count имеет вид: {\"elements\":[{\"type\":\"count\",\"tags\":{\"nodes\":\"X\",\"ways\":\"Y\",\"relations\":\"Z\"}}]}\n",
    "                total = 0\n",
    "                elements = data.get(\"elements\", [])\n",
    "                if elements:\n",
    "                    tags = elements[0].get(\"tags\", {})\n",
    "                    nodes = int(tags.get(\"nodes\", \"0\"))\n",
    "                    ways  = int(tags.get(\"ways\", \"0\"))\n",
    "                    rels  = int(tags.get(\"relations\", \"0\"))\n",
    "                    total = nodes + ways + rels\n",
    "\n",
    "                cache[key] = total\n",
    "                # периодически сбрасываем кэш\n",
    "                if attempt == 0 or attempt % 2 == 0:\n",
    "                    with open(CACHE_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "                        json.dump(cache, f, ensure_ascii=False)\n",
    "                return total\n",
    "            \n",
    "            except requests.exceptions.Timeout as e:\n",
    "                last_err = e\n",
    "                # backoff\n",
    "                sleep_s = min(45, 2 ** attempt) + random.random()\n",
    "                time.sleep(sleep_s)\n",
    "                continue\n",
    "            except requests.RequestException as e:\n",
    "                last_err = e\n",
    "                # на сетевые/серверные — следующая итерация/зеркало\n",
    "                sleep_s = 3 + random.random()\n",
    "                time.sleep(sleep_s)\n",
    "                continue\n",
    "\n",
    "    # если так и не получилось\n",
    "    cache[key] = 0\n",
    "    return 0\n",
    "\n",
    "# === Основной проход по строкам ===\n",
    "counts = []\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    try:\n",
    "        lat = float(row[\"lat\"])\n",
    "        lon = float(row[\"lon\"])\n",
    "    except Exception:\n",
    "        counts.append(0)\n",
    "        continue\n",
    "\n",
    "    if pd.isna(lat) or pd.isna(lon):\n",
    "        counts.append(0)\n",
    "        continue\n",
    "\n",
    "    c = overpass_count_schools(lat, lon, RADIUS_M)\n",
    "    counts.append(c)\n",
    "\n",
    "df[f\"schools_count_{RADIUS_M}m\"] = counts\n",
    "\n",
    "# финальный сброс кэша\n",
    "with open(CACHE_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(cache, f, ensure_ascii=False)\n",
    "\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(\"OK ->\", OUTPUT_CSV)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a4a8a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> cian_with_schools.csv | школ в bbox: 130701\n"
     ]
    }
   ],
   "source": [
    "import os, json, math, requests\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "INPUT_CSV   = \"cian_with_coords.csv\"\n",
    "OUTPUT_CSV  = \"cian_with_schools.csv\"\n",
    "SCHOOLS_GEOJSON = \"schools_bbox.geojson\"  # кэш скачанных школ\n",
    "RADIUS_M    = 800\n",
    "HEADERS = {\"User-Agent\": \"amenities-counter/1.1 (contact: your_email@example.com)\"}\n",
    "\n",
    "OVERPASS_URL = \"https://overpass-api.de/api/interpreter\"\n",
    "\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "df = df[df[\"lat\"].notna() & df[\"lon\"].notna()].copy()\n",
    "\n",
    "# --- 1) bbox всех точек с небольшим буфером (в градусах) ---\n",
    "min_lat, max_lat = df[\"lat\"].min(), df[\"lat\"].max()\n",
    "min_lon, max_lon = df[\"lon\"].min(), df[\"lon\"].max()\n",
    "\n",
    "# буфер ~2 км по широте; по долготе пересчёт через cos(lat)\n",
    "lat_buf_deg = 0.02\n",
    "lon_buf_deg = 0.02 / max(0.2, math.cos(math.radians((min_lat+max_lat)/2)))\n",
    "\n",
    "min_lat_b = min_lat - lat_buf_deg\n",
    "max_lat_b = max_lat + lat_buf_deg\n",
    "min_lon_b = min_lon - lon_buf_deg\n",
    "max_lon_b = max_lon + lon_buf_deg\n",
    "\n",
    "# --- 2) тянем все школы в bbox (одним запросом) и кэшируем ---\n",
    "if not os.path.exists(SCHOOLS_GEOJSON):\n",
    "    query = f\"\"\"\n",
    "[out:json][timeout:180];\n",
    "(\n",
    "  node[\"amenity\"=\"school\"]({min_lat_b},{min_lon_b},{max_lat_b},{max_lon_b});\n",
    "  way[\"amenity\"=\"school\"]({min_lat_b},{min_lon_b},{max_lat_b},{max_lon_b});\n",
    "  relation[\"amenity\"=\"school\"]({min_lat_b},{min_lon_b},{max_lat_b},{max_lon_b});\n",
    ");\n",
    "out center;  // для ways/relations отдаёт center {{lat,lon}}\n",
    "\"\"\"\n",
    "    resp = requests.post(OVERPASS_URL, data={\"data\": query}, headers=HEADERS, timeout=300)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    with open(SCHOOLS_GEOJSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False)\n",
    "else:\n",
    "    data = json.load(open(SCHOOLS_GEOJSON, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "# --- 3) достаём координаты школ ---\n",
    "schools = []\n",
    "for el in data.get(\"elements\", []):\n",
    "    if el.get(\"type\") == \"node\":\n",
    "        lat, lon = el.get(\"lat\"), el.get(\"lon\")\n",
    "    else:\n",
    "        center = el.get(\"center\") or {}\n",
    "        lat, lon = center.get(\"lat\"), center.get(\"lon\")\n",
    "    if lat is not None and lon is not None:\n",
    "        schools.append((float(lat), float(lon)))\n",
    "\n",
    "if not schools:\n",
    "    # нет школ — просто нули\n",
    "    df[f\"schools_count_{RADIUS_M}m\"] = 0\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(\"OK ->\", OUTPUT_CSV)\n",
    "    raise SystemExit\n",
    "\n",
    "# --- 4) строим BallTree в радианах и считаем для каждой точки ---\n",
    "import numpy as np\n",
    "\n",
    "sch_rad = np.radians(np.array(schools))   # (N,2) колонки: lat, lon\n",
    "tree = BallTree(sch_rad, metric=\"haversine\")\n",
    "\n",
    "pts_rad = np.radians(df[[\"lat\",\"lon\"]].to_numpy())\n",
    "\n",
    "EARTH_M = 6371008.8\n",
    "radius_rad = RADIUS_M / EARTH_M\n",
    "\n",
    "# вернёт для каждой точки список индексов школ в радиусе\n",
    "ind = tree.query_radius(pts_rad, r=radius_rad, count_only=False)\n",
    "counts = np.array([len(ix) for ix in ind], dtype=int)\n",
    "\n",
    "df[f\"schools_count_{RADIUS_M}m\"] = counts\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(\"OK ->\", OUTPUT_CSV, \"| школ в bbox:\", len(schools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35bd5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> cian_with_clinics.csv | клиник в bbox: 34115 | объектов: 24124\n"
     ]
    }
   ],
   "source": [
    "# ====== Turbo clinics counter: 1 Overpass fetch + local spatial count ======\n",
    "import os, json, math, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "INPUT_CSV   = \"cian_with_schools.csv\"\n",
    "OUTPUT_CSV  = \"cian_with_clinics.csv\"\n",
    "CLINICS_GEOJSON = \"clinics_bbox.geojson\"  # кэш скачанных клиник\n",
    "RADIUS_M    = 800\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"amenities-counter/1.2 (contact: nepesov82@gmail.com)\"}\n",
    "OVERPASS_URLS = [\n",
    "    \"https://overpass-api.de/api/interpreter\",\n",
    "    \"https://overpass.kumi.systems/api/interpreter\",\n",
    "    \"https://z.overpass-api.de/api/interpreter\",\n",
    "    \"https://overpass.openstreetmap.ru/api/interpreter\",\n",
    "    \"https://api.openstreetmap.fr/oapi/interpreter\",\n",
    "]\n",
    "\n",
    "# --- 0) Загружаем точки ---\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "if not {\"lat\",\"lon\"}.issubset(df.columns):\n",
    "    raise ValueError(\"Нужны колонки lat и lon.\")\n",
    "df = df[df[\"lat\"].notna() & df[\"lon\"].notna()].copy()\n",
    "\n",
    "# --- 1) bbox всех точек + небольшой буфер ---\n",
    "min_lat, max_lat = df[\"lat\"].min(), df[\"lat\"].max()\n",
    "min_lon, max_lon = df[\"lon\"].min(), df[\"lon\"].max()\n",
    "# ~2 км по широте; по долготе — через cos широты (чтобы буфер был сопоставим)\n",
    "lat_buf_deg = 0.02\n",
    "lon_buf_deg = max(0.01, 0.02 / max(0.2, math.cos(math.radians((min_lat+max_lat)/2))))\n",
    "min_lat_b = min_lat - lat_buf_deg\n",
    "max_lat_b = max_lat + lat_buf_deg\n",
    "min_lon_b = min_lon - lon_buf_deg\n",
    "max_lon_b = max_lon + lon_buf_deg\n",
    "\n",
    "# --- 2) тянем все клиники в bbox (один запрос) и кэшируем на диск ---\n",
    "def fetch_all_clinics_bbox() -> dict:\n",
    "    query = f\"\"\"\n",
    "    [out:json][timeout:180];\n",
    "    (\n",
    "      node[\"healthcare\"~\"^(clinic|medical_centre|hospital)$\"]({min_lat_b},{min_lon_b},{max_lat_b},{max_lon_b});\n",
    "      way[\"healthcare\"~\"^(clinic|medical_centre|hospital)$\"]({min_lat_b},{min_lon_b},{max_lat_b},{max_lon_b});\n",
    "      relation[\"healthcare\"~\"^(clinic|medical_centre|hospital)$\"]({min_lat_b},{min_lon_b},{max_lat_b},{max_lon_b});\n",
    "    );\n",
    "    out center;  // для ways/relations отдаёт center {{lat,lon}}\n",
    "    \"\"\"\n",
    "    last_err = None\n",
    "    for attempt in range(6):\n",
    "        for base in OVERPASS_URLS:\n",
    "            try:\n",
    "                r = requests.post(base, data={\"data\": query}, headers=HEADERS, timeout=300)\n",
    "                if r.status_code in (429, 502, 503, 504):\n",
    "                    ra = r.headers.get(\"Retry-After\")\n",
    "                    sleep_s = float(ra) if (ra and ra.isdigit()) else min(60, 2**attempt) + random.random()\n",
    "                    time.sleep(sleep_s); continue\n",
    "                r.raise_for_status()\n",
    "                return r.json()\n",
    "            except requests.RequestException as e:\n",
    "                last_err = e\n",
    "                time.sleep(min(45, 2**attempt) + random.random())\n",
    "                continue\n",
    "    raise RuntimeError(f\"Overpass не ответил: {last_err}\")\n",
    "\n",
    "if not os.path.exists(CLINICS_GEOJSON):\n",
    "    data = fetch_all_clinics_bbox()\n",
    "    with open(CLINICS_GEOJSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False)\n",
    "else:\n",
    "    data = json.load(open(CLINICS_GEOJSON, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "# --- 3) достаём координаты клиник ---\n",
    "clin_pts = []\n",
    "for el in data.get(\"elements\", []):\n",
    "    if el.get(\"type\") == \"node\":\n",
    "        lat, lon = el.get(\"lat\"), el.get(\"lon\")\n",
    "    else:\n",
    "        c = el.get(\"center\") or {}\n",
    "        lat, lon = c.get(\"lat\"), c.get(\"lon\")\n",
    "    if lat is not None and lon is not None:\n",
    "        clin_pts.append((float(lat), float(lon)))\n",
    "\n",
    "# Если клиник нет в bbox — просто нули и выходим\n",
    "if not clin_pts:\n",
    "    df[f\"clinics_count_{RADIUS_M}m\"] = 0\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(\"OK ->\", OUTPUT_CSV, \"| клиник найдено: 0\")\n",
    "    raise SystemExit\n",
    "\n",
    "clin_np = np.radians(np.array(clin_pts))  # (N,2) lat,lon в радианах\n",
    "pts_np  = np.radians(df[[\"lat\",\"lon\"]].to_numpy())\n",
    "\n",
    "EARTH_M = 6371008.8\n",
    "radius_rad = RADIUS_M / EARTH_M\n",
    "\n",
    "\n",
    "def count_with_balltree(pts_rad, ref_rad, r_rad):\n",
    "    try:\n",
    "        from sklearn.neighbors import BallTree\n",
    "        tree = BallTree(ref_rad, metric=\"haversine\")\n",
    "        ind = tree.query_radius(pts_rad, r=r_rad, count_only=False)\n",
    "        return np.array([len(ix) for ix in ind], dtype=int)\n",
    "    except Exception:\n",
    "\n",
    "        B = 5000  # размер батча по точкам\n",
    "        ref_lat = ref_rad[:,0]; ref_lon = ref_rad[:,1]\n",
    "        out = np.zeros(pts_rad.shape[0], dtype=int)\n",
    "        for i in range(0, pts_rad.shape[0], B):\n",
    "            a = pts_rad[i:i+B]\n",
    "            # broadcasting: (b,1) против (1,n)\n",
    "            dlat = a[:,[0]] - ref_lat[None,:]\n",
    "            dlon = a[:,[1]] - ref_lon[None,:]\n",
    "            # формула гаверсинуса\n",
    "            sin_dlat = np.sin(dlat/2)\n",
    "            sin_dlon = np.sin(dlon/2)\n",
    "            aa = sin_dlat**2 + np.cos(a[:,[0]])*np.cos(ref_lat[None,:])*(sin_dlon**2)\n",
    "            dist = 2*np.arcsin(np.minimum(1, np.sqrt(aa)))  # радианы\n",
    "            out[i:i+B] = (dist <= r_rad).sum(axis=1)\n",
    "        return out\n",
    "\n",
    "counts = count_with_balltree(pts_np, clin_np, radius_rad)\n",
    "\n",
    "df[f\"clinics_count_{RADIUS_M}m\"] = counts.astype(int)\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "print(\"OK ->\", OUTPUT_CSV, \"| клиник в bbox:\", len(clin_pts), \"| объектов:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bec9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Использую кэш: kindergartens_bbox.geojson\n",
      "Найдено детсадов: 51938\n",
      "✅ Готово → cian_with_kindergartens.csv | объектов: 24124 | детсадов: 51938\n"
     ]
    }
   ],
   "source": [
    "# сбор с детских садов \n",
    "import os, json, math, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "INPUT_CSV   = \"cian_with_clinics.csv\"\n",
    "OUTPUT_CSV  = \"cian_with_kindergartens.csv\"\n",
    "CACHE_JSON  = \"kindergartens_bbox.geojson\"   # кэш скачанных садиков\n",
    "RADIUS_M    = 800\n",
    "HEADERS = {\"User-Agent\": \"amenities-counter/1.3 (contact: nepesov82@gmail.com)\"}\n",
    "OVERPASS_URLS = [\n",
    "    \"https://overpass-api.de/api/interpreter\",\n",
    "    \"https://overpass.kumi.systems/api/interpreter\",\n",
    "    \"https://z.overpass-api.de/api/interpreter\",\n",
    "    \"https://overpass.openstreetmap.ru/api/interpreter\",\n",
    "    \"https://api.openstreetmap.fr/oapi/interpreter\",\n",
    "]\n",
    "\n",
    "# тут коорды загружаются \n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "if not {\"lat\", \"lon\"}.issubset(df.columns):\n",
    "    raise ValueError(\"В CSV должны быть колонки lat, lon\")\n",
    "\n",
    "df = df[df[\"lat\"].notna() & df[\"lon\"].notna()].copy()\n",
    "\n",
    "min_lat, max_lat = df[\"lat\"].min(), df[\"lat\"].max()\n",
    "min_lon, max_lon = df[\"lon\"].min(), df[\"lon\"].max()\n",
    "lat_buf_deg = 0.02\n",
    "lon_buf_deg = max(0.01, 0.02 / max(0.2, math.cos(math.radians((min_lat+max_lat)/2))))\n",
    "\n",
    "min_lat_b = min_lat - lat_buf_deg\n",
    "max_lat_b = max_lat + lat_buf_deg\n",
    "min_lon_b = min_lon - lon_buf_deg\n",
    "max_lon_b = max_lon + lon_buf_deg\n",
    "\n",
    "def fetch_all_kindergartens() -> dict:\n",
    "    query = f\"\"\"\n",
    "    [out:json][timeout:180];\n",
    "    (\n",
    "      node[\"amenity\"=\"kindergarten\"]({min_lat_b},{min_lon_b},{max_lat_b},{max_lon_b});\n",
    "      way[\"amenity\"=\"kindergarten\"]({min_lat_b},{min_lon_b},{max_lat_b},{max_lon_b});\n",
    "      relation[\"amenity\"=\"kindergarten\"]({min_lat_b},{min_lon_b},{max_lat_b},{max_lon_b});\n",
    "    );\n",
    "    out center;  // для ways/relations отдаёт center {{lat,lon}}\n",
    "    \"\"\"\n",
    "    last_err = None\n",
    "    for attempt in range(6):\n",
    "        for base in OVERPASS_URLS:\n",
    "            try:\n",
    "                r = requests.post(base, data={\"data\": query}, headers=HEADERS, timeout=300)\n",
    "                if r.status_code in (429, 502, 503, 504):\n",
    "                    ra = r.headers.get(\"Retry-After\")\n",
    "                    sleep_s = float(ra) if ra and ra.isdigit() else min(60, 2**attempt) + random.random()\n",
    "                    time.sleep(sleep_s)\n",
    "                    continue\n",
    "                r.raise_for_status()\n",
    "                return r.json()\n",
    "            except requests.RequestException as e:\n",
    "                last_err = e\n",
    "                time.sleep(min(45, 2**attempt) + random.random())\n",
    "                continue\n",
    "    raise RuntimeError(f\"Overpass не ответил: {last_err}\")\n",
    "\n",
    "\n",
    "if not os.path.exists(CACHE_JSON):\n",
    "    print(\"Загружаю детские сады из Overpass...\")\n",
    "    data = fetch_all_kindergartens()\n",
    "    with open(CACHE_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False)\n",
    "else:\n",
    "    print(\"Использую кэш:\", CACHE_JSON)\n",
    "    data = json.load(open(CACHE_JSON, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "\n",
    "kindergartens = []\n",
    "for el in data.get(\"elements\", []):\n",
    "    if el.get(\"type\") == \"node\":\n",
    "        lat, lon = el.get(\"lat\"), el.get(\"lon\")\n",
    "    else:\n",
    "        c = el.get(\"center\") or {}\n",
    "        lat, lon = c.get(\"lat\"), c.get(\"lon\")\n",
    "    if lat is not None and lon is not None:\n",
    "        kindergartens.append((float(lat), float(lon)))\n",
    "\n",
    "if not kindergartens:\n",
    "    print(\"В bbox не найдено детских садов.\")\n",
    "    df[f\"kindergartens_count_{RADIUS_M}m\"] = 0\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    exit()\n",
    "\n",
    "print(f\"Найдено детсадов: {len(kindergartens)}\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "EARTH_M = 6371008.8\n",
    "radius_rad = RADIUS_M / EARTH_M\n",
    "\n",
    "pts_rad = np.radians(df[[\"lat\",\"lon\"]].to_numpy())\n",
    "kinder_rad = np.radians(np.array(kindergartens))\n",
    "\n",
    "try:\n",
    "    from sklearn.neighbors import BallTree\n",
    "    tree = BallTree(kinder_rad, metric=\"haversine\")\n",
    "    ind = tree.query_radius(pts_rad, r=radius_rad, count_only=False)\n",
    "    counts = np.array([len(i) for i in ind], dtype=int)\n",
    "except ImportError:\n",
    "    # Fallback без sklearn: векторизованный подсчёт\n",
    "    print(\"ℹ️ scikit-learn не установлен, считаю в numpy (чуть дольше)...\")\n",
    "    B = 5000\n",
    "    ref_lat, ref_lon = kinder_rad[:,0], kinder_rad[:,1]\n",
    "    counts = np.zeros(pts_rad.shape[0], dtype=int)\n",
    "    for i in range(0, pts_rad.shape[0], B):\n",
    "        a = pts_rad[i:i+B]\n",
    "        dlat = a[:,[0]] - ref_lat[None,:]\n",
    "        dlon = a[:,[1]] - ref_lon[None,:]\n",
    "        sin_dlat, sin_dlon = np.sin(dlat/2), np.sin(dlon/2)\n",
    "        aa = sin_dlat**2 + np.cos(a[:,[0]])*np.cos(ref_lat[None,:])*(sin_dlon**2)\n",
    "        dist = 2*np.arcsin(np.minimum(1, np.sqrt(aa)))\n",
    "        counts[i:i+B] = (dist <= radius_rad).sum(axis=1)\n",
    "\n",
    "df[f\"kindergartens_count_{RADIUS_M}m\"] = counts\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "print(f\"Готово → {OUTPUT_CSV} | объектов: {len(df)} | детсадов: {len(kindergartens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43660b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
